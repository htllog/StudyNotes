# Prompt 使用

如何理解 Prompt ?

> prompt 通常指的是一个输入的文本段落或短语，作为生成模型输出的起点或引导。prompt 可以是一个问题、一段文字描述、一段对话或任何形式的文本输入，模型会基于 prompt 所提供的上下文和语义信息，生成相应的输出文本。



## 基础模式

* 特定指令（By specific）：在这种模式下，我们给模型提供一些特定信息，例如问题或关键词，模型需要生成与这些信息相关的文本。这种模式通常用于生成答案、解释或推荐等。特定信息可以是单个问题或多个关键词，具体取决于任务的要求。
* 指令模板（Instruction Template）：在这种模式下，我们给模型提供一些明确的指令，模型需要根据这些指令生成文本。这种模式通常用于生成类似于技术说明书、操作手册等需要明确指令的文本。指令可以是单个句子或多个段落，具体取决于任务的要求。
* 代理模式（By proxy）：在这种模式下，可以充当了一个代理，代表某个实体（例如人、角色、机器人等）进行操作或交互。代理模式的核心思想是引入一个中介对象来控制对实际对象的访问，从而实现一定程度上的隔离和保护。诸如于在 ChatGPT 中，"act as xxx" 可以让 ChatGPT 充当一个代理，扮演某个角色或实体的身份，以此来处理与该角色或实体相关的任务或请求。
* 示例模式（By demonstration）：在这种模式下，我们给模型提供一些示例文本，模型需要生成与示例文本类似的文本。这种模式通常用于生成类似于给定示例的文本，例如自动生成电子邮件、产品描述、新闻报道等。示例文本可以是单个句子或多个段落，具体取决于任务的要求。

## 特定指令 (By specific)

> 在这种模式下，我们给模型提供一些特定信息，例如问题或关键词，模型需要生成与这些信息相关的文本。这种模式通常用于生成答案、解释或推荐等。特定信息可以是单个问题或多个关键词，具体取决于任务的要求。



![img](https://raw.githubusercontent.com/prompt-engineering/prompt-patterns/c53f66824e9b62d07ee687648bbd328577bc897e/patterns/specific.svg)



* 问答型：用户提供问题，AI 生成答案

  ```
  什么是机器学习
  ```

* 分类型：用户提供问题 or 任务描述，AI 生成答案

  ```
  如何做一个巧克力蛋糕
  ```

* 翻译型：用户提供文本，AI 进行翻译

  ```
  翻译一下："Template"
  ```

* 摘要型：用户提供文本，AI 生成文本摘要

  ```
  用户输入一篇文章，ChatGPT 生成该文章的摘要
  ```



## 指令模板 (Instruction Template)

> 在这种模式下，我们给模型提供一些明确的指令，模型需要根据这些指令生成文本。这种模式通常用于生成类似于技术说明书、操作手册等需要明确指令的文本。指令可以是单个句子或多个段落，具体取决于任务的要求。



![img](https://raw.githubusercontent.com/prompt-engineering/prompt-patterns/c53f66824e9b62d07ee687648bbd328577bc897e/patterns/instruction.svg)



EG：

```
使用 STAR 原则与下面的格式总结一下这段话：

"""
最近几天，因为工作 + 兴趣的原则，我在研究用 text 2 image 来展示如何演进 prompt、用 text 2 article 来展示充足 prompt 的优点、结合 GitHub Copliot 来实现 prompt 完成工作。然后，我在本地部署了一个 Stable Diffusion、使用 ChatGPT 写作展示 text 2 article、在 IDEA 中使用 GitHub Copilot。最后，得到了多篇文章和好多的文章阅读量、几个 Jupyter 代码段、以及一些经验。
"""

情境(Situation): 
任务(Task): <comma_separated_list_of_task>
行动(Action):  -||-
结果(Result):  -||-

```



## 代理模式 (By proxy)

> Proxy 模式是指用户可以要求 ChatGPT 以特定的身份、角色或者身份扮演某个特定的人、角色或对象来生成回答。这种模式通常用于模拟某个特定人物的语言风格和语境，生成特定情境下的对话、回答或其他形式的文本。



![img](https://raw.githubusercontent.com/prompt-engineering/prompt-patterns/c53f66824e9b62d07ee687648bbd328577bc897e/patterns/proxy.svg)



当使用 ChatGPT 来代替某个人或实体时，可以使用 by proxy 模式。

EG : 

```
我是一个python程序员，我想实现运动记录卡路里功能，请帮我实现
```



## 增强 Prompt

**符号化模式：**

> 符号化方法通常通过定义符号、符号之间的关系以及基于这些关系的规则来表示知识。



![img](https://raw.githubusercontent.com/prompt-engineering/prompt-patterns/c53f66824e9b62d07ee687648bbd328577bc897e/patterns/prompt-symbol-pattern.svg)



即：可以创建一个符号来表示特写的规则，EG：

```
"""
我们来玩一个名为 gkzw 的写作游戏，每当我说 gkzw，你开始写作，规则如下：

1. 字数不少于 200 字。
2. 文中必须出现 "小明"。

明白了吗？
"""
```

围绕该模式，我们可以创建复制的规则。



## 反向 Prompt 模式

> Negative prompt（负向提示）是一种在使用语言模型时，针对模型输出不希望的结果而设置的一种文本输入方式。通过使用负向提示，可以帮助模型避免输出不良、不准确或不恰当的文本。



具体来说，负向提示通常是以否定的形式呈现的:

1. 例如在文本生成任务中，使用“不要写...”、“不要提及...”、“不要使用...”等方式来限制模型生成不想要的文本。
2. 在情感分析任务中，使用“不是...”、“并不...”等方式来指示模型识别出一段文本的负面情感。
3. 在 QA （问答）任务中，使用“不是...”、“不包括...”等方式来指示模型回答问题时避免输出错误或不准确的答案。

EG：

```
我们能玩一个名为 kfc 的谜语创作游戏，当我说 " kfc "，你写一个谜题，要求：

1. 不少于 200 字
2. 谜题不能出现肯德基、星期四、KFC
3. 正文可以夹杂小语种语言，如 """他说：Ciao"""
4. 谜底必须是 ###原来今天是肯德基疯狂星期四！！###

格式类似于：

....
```



## 再生成模式

> 根据 AI 提供的信息，再让 AI 生成内容。



EG：

当我们无法确定我们的 prompt 是否准确，便可以通过 AI 来帮我们丰富 prompt 。如在基于编程、绘画、创作使用中：

```
phodal :  我想写一段话描述一张照片，帮我美化一下：一年轻女子穿着裙子，背对着镜头，在海边看着日落，太阳已经到地平线下面了，她的头发在风中飘动。
```

```
ChatGPT :  这张照片中的场景令人心醉，一位年轻女子穿着一条裙子，站在海边，背对着镜头，凝视着地平线下的夕阳。太阳已经沉入了海面，一片金黄色的光芒在海面上弥漫，照亮了整片海洋，仿佛这个时刻被定格在了时间的某个角落里。女子的头发随着微风轻轻飘动，轮廓被余晖映照得柔和而温暖。她的目光凝视着远方，仿佛在思考着生命的意义和无尽的未来。这张照片中蕴含着一种深刻的内涵，让人感受到时间和自然的力量，也让人思考着自己在这个宏大而美丽的世界中的角色和意义。
```

再通过删去不合适的词，根据需要进行润色后再创作：

```
phodal：翻译成英语
```

然后对翻译的结果再提炼扔至 Stable Diffusion 中，根据获得的图片结果，根据实际需要进行修改



## 概念抽象

> 对于 ChatGPT 尚不存在的概念，可以通过 Google 相关的内容之后，由 ChatGPT 进行总结



EG :

```
根据下面的文本重新解释一下 ControlNet：

- 官网介绍：ControlNet is a neural network structure to control diffusion models by adding extra conditions.
- 模式：根据给的底图，生成一个类似建模效果（法线贴图）的中间图，再生成图片 
- 场景：用来实现骨骼绑定、精准控线、线稿上色、依据深度图结构透视精准重绘等。
```

Result :

```
根据给出的文本，ControlNet是一种神经网络结构，旨在通过添加额外条件来控制扩散模型。在特定场景下，ControlNet被用于生成类似建模效果（法线贴图）的中间图和相关的图像。这种技术可以被应用于多个领域，如骨骼绑定、精准控线、线稿上色、深度图结构透视精准重绘等。

具体来说，ControlNet技术可以被用来控制模型的扩散过程，从而提取特定的信息并生成新的图像。在骨骼绑定、线稿上色等场景中，ControlNet技术可以被用来增强图像，使其更加真实和生动。在依据深度图结构透视精准重绘的场景中，ControlNet技术可以被用来根据图像的深度信息，生成精确的重绘图像，从而提高图像的真实感和逼真度。
```

概括和缩短：

```
能用一句话解释一下 ControlNet 吗?
```

Result :

```
ControlNet 是一种神经网络结构，通过添加额外的条件来控制扩散模型，从而实现图像增强、重构和生成等功能。
```



## 概念对齐

EG :  

在 ChatGPT 中对于自举的理解是不符合我们需求: 



![image-20230713191047023](/Users/zhuangzeping/Library/Application Support/typora-user-images/image-20230713191047023.png)



**第一步：定义**

> 自举是指就编译器可以自行编译自己的编译器。 实现方法就是这个编译器的作者用这个语言的一些特性来编写编译器并在该编译器中支持这些自己使用到的特性。

**第二步：试探**

> 将自举应用在游戏领域，应该是怎样的？

**第三步：确认理解**

> 那么，抽象一下我们新定义的自举？



![image-20230713191515727](/Users/zhuangzeping/Library/Application Support/typora-user-images/image-20230713191515727.png)

